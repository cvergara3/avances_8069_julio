{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d0961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob, numpy as np\n",
    "from collections import Counter\n",
    "from obspy.io.segy.segy import _read_segy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pytorch_msssim import SSIM\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from math import log10\n",
    "\n",
    "BASE_DIR = \"/home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 2\"\n",
    "H, W = 512, 4096\n",
    "BATCH = 1\n",
    "EPOCHS = 20\n",
    "LR = 1e-4\n",
    "PCTS = list(range(10, 100, 10))\n",
    "PRINT_MAX_EX = 5       \n",
    "\n",
    "GLOBAL_SEED = 42\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "\n",
    "def print_header(title):\n",
    "    print(\"\\n\" + \"=\"*10 + f\" {title} \" + \"=\"*10)\n",
    "\n",
    "def print_basic_stats(name, arr):\n",
    "    arr_np = arr if isinstance(arr, np.ndarray) else arr.cpu().numpy()\n",
    "    print(f\"[{name}] shape={arr_np.shape}, dtype={arr_np.dtype}, \"\n",
    "          f\"min={np.nanmin(arr_np):.4f}, max={np.nanmax(arr_np):.4f}, \"\n",
    "          f\"mean={np.nanmean(arr_np):.4f}, std={np.nanstd(arr_np):.4f}\")\n",
    "\n",
    "def print_tag_dist(label, tags):\n",
    "    c = Counter(tags.tolist() if isinstance(tags, np.ndarray) else tags)\n",
    "    print(f\"[{label}] N={len(tags)} | dist={dict(c)}\")\n",
    "\n",
    "def sanity_no_nan_inf(name, arr):\n",
    "    arr_np = arr if isinstance(arr, np.ndarray) else arr.cpu().numpy()\n",
    "    n_nan = np.isnan(arr_np).sum()\n",
    "    n_inf = np.isinf(arr_np).sum()\n",
    "    assert n_nan == 0 and n_inf == 0, f\"{name}: NaN={n_nan}, Inf={n_inf}\"\n",
    "\n",
    "def check_divisible_by_8(h, w):\n",
    "    for val, nm in [(h, \"H\"), (w, \"W\")]:\n",
    "        assert val % 8 == 0, f\"{nm} debe ser múltiplo de 8 para U-Net: {val}\"\n",
    "\n",
    "def check_train_test_disjoint(idx_tr, idx_te):\n",
    "    inter = set(idx_tr.tolist()).intersection(set(idx_te.tolist()))\n",
    "    assert len(inter) == 0, f\"Train/Test con intersección! {inter}\"\n",
    "\n",
    "def verify_subsampling(X, target_frac):\n",
    "    N, nrec, _ = X.shape\n",
    "    ks = min(N, PRINT_MAX_EX)\n",
    "    fracs = []\n",
    "    for i in range(ks):\n",
    "        zero_rows = np.where(np.all(X[i] == 0, axis=1))[0]\n",
    "        fracs.append(len(zero_rows)/nrec)\n",
    "    print(f\"[Check Submuestreo] target={target_frac:.2f}, \"\n",
    "          f\"ejemplos={fracs} (prom={np.mean(fracs):.3f})\")\n",
    "\n",
    "def gpu_info(device):\n",
    "    if device.type == \"cuda\":\n",
    "        print(f\"[GPU] {torch.cuda.get_device_name(0)} | \"\n",
    "              f\"cap={torch.cuda.get_device_capability(0)} | \"\n",
    "              f\"mem_alloc={torch.cuda.memory_allocated()/1e9:.2f} GB | \"\n",
    "              f\"mem_reserved={torch.cuda.memory_reserved()/1e9:.2f} GB\")\n",
    "    else:\n",
    "        print(\"[GPU] No CUDA: usando CPU\")\n",
    "\n",
    "def tag(fname):\n",
    "    m = re.search(r'shot_(y\\d{2})_', os.path.basename(fname).lower())\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def load_all(base_dir):\n",
    "    pats = [\"shot_y0[1-7]_*.sgy\", \"shot_y0[1-7]_*.segy\"]\n",
    "    files = sorted(sum([glob.glob(os.path.join(base_dir, p)) for p in pats], []))\n",
    "    files = [f for f in files if tag(f) in {f\"y0{i}\" for i in range(1,8)}]\n",
    "    arrs, tags_list = [], []\n",
    "    for f in files:\n",
    "        st = _read_segy(f, headonly=False)\n",
    "        arr = np.array([tr.data for tr in st.traces], dtype=np.float32)\n",
    "        arrs.append(arr)\n",
    "        tags_list.append(tag(f))\n",
    "    print_header(\"Carga de archivos\")\n",
    "    print(f\"Total archivos: {len(files)} | ejemplos: {files[:PRINT_MAX_EX]}\")\n",
    "    for i in range(min(3, len(arrs))):\n",
    "        print(f\"  - arr[{i}] shape={arrs[i].shape}, tag={tags_list[i]}\")\n",
    "    return np.stack(arrs, 0), np.array(tags_list)\n",
    "\n",
    "gathers, tags = load_all(BASE_DIR) \n",
    "print_header(\"Antes de recorte\")\n",
    "print_basic_stats(\"gathers_raw\", gathers)\n",
    "print_tag_dist(\"tags_total\", tags)\n",
    "\n",
    "assert gathers.shape[1] >= H and gathers.shape[2] >= W, \"Dimensiones de archivo < H/W\"\n",
    "check_divisible_by_8(H, W)\n",
    "gathers = gathers[:, :H, :W].copy() \n",
    "print_header(\"Después de recorte\")\n",
    "print_basic_stats(\"gathers\", gathers)\n",
    "sanity_no_nan_inf(\"gathers\", gathers)\n",
    "\n",
    "idx = np.arange(len(tags))\n",
    "idx_tr, idx_te = train_test_split(\n",
    "    idx, test_size=0.2, random_state=42, shuffle=True)\n",
    "check_train_test_disjoint(idx_tr, idx_te)\n",
    "Gtr, Gte = gathers[idx_tr], gathers[idx_te]\n",
    "Ttr, Tte = tags[idx_tr], tags[idx_te]\n",
    "print_header(\"Split Train/Test\")\n",
    "print(f\"N_total={len(tags)} | N_tr={len(Ttr)} | N_te={len(Tte)}\")\n",
    "print_tag_dist(\"tags_train\", Ttr)\n",
    "print_tag_dist(\"tags_test\", Tte)\n",
    "\n",
    "def norm_trace(x):\n",
    "    m = np.max(np.abs(x), axis=2, keepdims=True) + 1e-6\n",
    "    return x / m\n",
    "\n",
    "Ytr, Yte = norm_trace(Gtr), norm_trace(Gte)\n",
    "print_header(\"Normalización\")\n",
    "print_basic_stats(\"Ytr (targets train)\", Ytr)\n",
    "print_basic_stats(\"Yte (targets test)\", Yte)\n",
    "sanity_no_nan_inf(\"Ytr\", Ytr)\n",
    "sanity_no_nan_inf(\"Yte\", Yte)\n",
    "print(\"Rangos esperados ~[-1,1]. data_range=2.0 para SSIM.\")\n",
    "\n",
    "def subsample_all_with_idx(X, frac, seed):\n",
    "    \"\"\"\n",
    "    Anula 'frac' de receptores en CADA shot (filas completas a cero).\n",
    "    Devuelve X modificado y lista de arrays con los índices anulados por shot.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    N, nrec, _ = X.shape\n",
    "    nrem = int(round(frac * nrec))\n",
    "    idxs_removidos = []\n",
    "    for i in range(N):\n",
    "        if nrem > 0:\n",
    "            idx0 = np.sort(rng.choice(nrec, size=nrem, replace=False))\n",
    "            X[i, idx0, :] = 0.0\n",
    "            idxs_removidos.append(idx0)\n",
    "        else:\n",
    "            idxs_removidos.append(np.array([], dtype=int))\n",
    "    return X, idxs_removidos\n",
    "\n",
    "class UNet2DFull(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        def blk(cin, cout):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(cin, cout, 3, padding=1),\n",
    "                nn.BatchNorm2d(cout), nn.LeakyReLU(0.01, True),\n",
    "                nn.Conv2d(cout, cout, 3, padding=1),\n",
    "                nn.BatchNorm2d(cout), nn.LeakyReLU(0.01, True)\n",
    "            )\n",
    "        self.e1, self.p1 = blk(1,64), nn.MaxPool2d(2,2)\n",
    "        self.e2, self.p2 = blk(64,128), nn.MaxPool2d(2,2)\n",
    "        self.e3, self.p3 = blk(128,256), nn.MaxPool2d(2,2)\n",
    "        self.bott = blk(256,512)\n",
    "        self.u3 = nn.ConvTranspose2d(512,256,2,2); self.d3 = blk(512,256)\n",
    "        self.u2 = nn.ConvTranspose2d(256,128,2,2); self.d2 = blk(256,128)\n",
    "        self.u1 = nn.ConvTranspose2d(128, 64,2,2); self.d1 = blk(128, 64)\n",
    "        self.out = nn.Conv2d(64,1,1)\n",
    "    def forward(self,x):\n",
    "        e1=self.e1(x); p1=self.p1(e1)\n",
    "        e2=self.e2(p1); p2=self.p2(e2)\n",
    "        e3=self.e3(p2); p3=self.p3(e3)\n",
    "        b=self.bott(p3)\n",
    "        u3=self.u3(b); d3=self.d3(torch.cat([u3, self.crop(e3,u3)],1))\n",
    "        u2=self.u2(d3); d2=self.d2(torch.cat([u2, self.crop(e2,u2)],1))\n",
    "        u1=self.u1(d2); d1=self.d1(torch.cat([u1, self.crop(e1,u1)],1))\n",
    "        return torch.tanh(self.out(d1))\n",
    "    @staticmethod\n",
    "    def crop(a,b):\n",
    "        _,_,h,w=b.shape; _,_,H,W=a.shape\n",
    "        dh,dw=(H-h)//2,(W-w)//2\n",
    "        return a[:,:,dh:dh+h, dw:dw+w]\n",
    "\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def eval_metrics_removed_only(model, Xe, Ye, device, return_counts=False):\n",
    "    \"\"\"\n",
    "    Métricas SOLO sobre las trazas eliminadas (filas todo-cero en la entrada).\n",
    "    Ignora shots sin trazas eliminadas. Devuelve promedio y (opcional) conteos.\n",
    "    \"\"\"\n",
    "    MSE, PSNR, SSIMg, SNR = [], [], [], []\n",
    "    shots_used = 0\n",
    "    total_removed_traces = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(Ye.shape[0]):\n",
    "            yt = Ye[i, 0].cpu().numpy()     \n",
    "            xi = Xe[i, 0].cpu().numpy()       \n",
    "            idx0 = np.where(np.all(xi == 0, axis=1))[0]\n",
    "            if len(idx0) == 0:\n",
    "                continue\n",
    "\n",
    "            yp = model(Xe[i:i+1].to(device)).cpu().squeeze().numpy() \n",
    "            ytn = yt[idx0]\n",
    "            ypn = yp[idx0]\n",
    "\n",
    "            mse = np.mean((ytn - ypn)**2)\n",
    "            amp = np.ptp(ytn) + 1e-8\n",
    "            psn = 20 * np.log10(amp / (np.sqrt(mse + 1e-12))) if mse > 0 else float('inf')\n",
    "            ssi = np.mean([ssim(ytn[j], ypn[j], data_range=2) for j in range(ytn.shape[0])])\n",
    "            snr = 10 * np.log10((np.mean(ytn**2) + 1e-12) / (mse + 1e-12))\n",
    "\n",
    "            MSE.append(mse); PSNR.append(psn); SSIMg.append(ssi); SNR.append(snr)\n",
    "            shots_used += 1\n",
    "            total_removed_traces += len(idx0)\n",
    "\n",
    "    if len(MSE) == 0:\n",
    "        out = {\"MSE\": None, \"PSNR\": None, \"SSIM\": None, \"SNR\": None}\n",
    "        return (out, (0, 0)) if return_counts else out\n",
    "\n",
    "    mean = lambda v: float(np.mean(v)) if len(v) else None\n",
    "    out = {\"MSE\": mean(MSE), \"PSNR\": mean(PSNR), \"SSIM\": mean(SSIMg), \"SNR\": mean(SNR)}\n",
    "    return (out, (shots_used, total_removed_traces)) if return_counts else out\n",
    "\n",
    "def visualizar_comparacion(x_input, y_pred, y_true, titulo_extra=\"\"):\n",
    "    error = np.abs(y_pred - y_true)\n",
    "    vmin, vmax = -1, 1\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(24, 6))\n",
    "\n",
    "    im0 = axs[0].imshow(x_input.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
    "    axs[0].set_title(\"Input (trazas anuladas)\")\n",
    "    axs[0].set_xlabel(\"Receptor\"); axs[0].set_ylabel(\"Tiempo\")\n",
    "    fig.colorbar(im0, ax=axs[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "    im1 = axs[1].imshow(y_pred.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
    "    axs[1].set_title(\"Predicción (U-Net)\")\n",
    "    axs[1].set_xlabel(\"Receptor\"); axs[1].set_ylabel(\"Tiempo\")\n",
    "    fig.colorbar(im1, ax=axs[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "    im2 = axs[2].imshow(y_true.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
    "    axs[2].set_title(\"Shot original\")\n",
    "    axs[2].set_xlabel(\"Receptor\"); axs[2].set_ylabel(\"Tiempo\")\n",
    "    fig.colorbar(im2, ax=axs[2], fraction=0.046, pad=0.04)\n",
    "\n",
    "    im3 = axs[3].imshow(error.T, cmap='inferno', aspect='auto', origin='upper')\n",
    "    axs[3].set_title(\"Error absoluto\")\n",
    "    axs[3].set_xlabel(\"Receptor\"); axs[3].set_ylabel(\"Tiempo\")\n",
    "    fig.colorbar(im3, ax=axs[3], fraction=0.046, pad=0.04)\n",
    "\n",
    "    fig.suptitle(f\"Comparación: Entrada — Predicción — Original — Error {titulo_extra}\", fontsize=14)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print_header(\"Dispositivo\")\n",
    "print(f\"device={device} | PCTS={PCTS} | BATCH={BATCH} | EPOCHS={EPOCHS}\")\n",
    "gpu_info(device)\n",
    "\n",
    "curvas_loss = {}\n",
    "resultados_metricas = {}\n",
    "\n",
    "for pct in PCTS:\n",
    "    print_header(f\"Submuestreo {pct}%\")\n",
    "    frac = pct / 100.0\n",
    "\n",
    "    Xtr = Ytr.copy()\n",
    "    Xte = Yte.copy()\n",
    "\n",
    "    seed_pct = 1000 + pct\n",
    "    Xtr, idxs_removidos_train = subsample_all_with_idx(Xtr, frac, seed=seed_pct)\n",
    "    Xte, idxs_removidos_test  = subsample_all_with_idx(Xte, frac, seed=seed_pct)\n",
    "\n",
    "    verify_subsampling(Xtr, frac)\n",
    "    verify_subsampling(Xte, frac)\n",
    "    sanity_no_nan_inf(\"Xtr\", Xtr)\n",
    "    sanity_no_nan_inf(\"Xte\", Xte)\n",
    "\n",
    "    Xt = torch.from_numpy(Xtr).unsqueeze(1).to(device) \n",
    "    Yt = torch.from_numpy(Ytr).unsqueeze(1).to(device) \n",
    "    Xe = torch.from_numpy(Xte).unsqueeze(1).to(device) \n",
    "    Ye = torch.from_numpy(Yte).unsqueeze(1).to(device)  \n",
    "\n",
    "    print_basic_stats(\"Tensor Xt\", Xt)\n",
    "    print_basic_stats(\"Tensor Yt\", Yt)\n",
    "    print(f\"Dataset sizes -> train={Xt.shape[0]}, test={Xe.shape[0]}\")\n",
    "    loader = DataLoader(TensorDataset(Xt, Yt), batch_size=BATCH, shuffle=True)\n",
    "\n",
    "    model = UNet2DFull().to(device)\n",
    "    print(f\"Parámetros del modelo: {count_params(model):,}\")\n",
    "\n",
    "    opt   = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    crit  = SSIM(data_range=2.0, size_average=True, channel=1)\n",
    "\n",
    "    loss_hist = []\n",
    "    model.train()\n",
    "    for ep in range(EPOCHS):\n",
    "        run = 0.0\n",
    "        for xb, yb in tqdm(loader, desc=f\"{pct}% | Época {ep+1}/{EPOCHS}\", leave=False):\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            yp = model(xb)\n",
    "            loss = 1 - crit(yp, yb)\n",
    "            loss.backward(); opt.step()\n",
    "            run += loss.item()\n",
    "        ep_loss = run / len(loader)\n",
    "        loss_hist.append(ep_loss)\n",
    "        print(f\"[{pct}%] Epoch {ep+1:02d}/{EPOCHS} | loss(1-SSIM)={ep_loss:.6f}\")\n",
    "\n",
    "    curvas_loss[str(pct)] = loss_hist\n",
    "\n",
    "    idx_vis = None\n",
    "    for i in range(Xe.shape[0]):\n",
    "        xi = Xe[i, 0].detach().cpu().numpy()\n",
    "        if np.any(np.all(xi == 0, axis=1)):\n",
    "            idx_vis = i\n",
    "            break\n",
    "    if idx_vis is None:\n",
    "        print(\"⚠ No se encontró shot de test con trazas anuladas; usando idx 0.\")\n",
    "        idx_vis = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(Xe[idx_vis:idx_vis+1]).cpu().squeeze().numpy()\n",
    "        entrada = Xe[idx_vis, 0].cpu().numpy()\n",
    "        real = Ye[idx_vis, 0].cpu().numpy()\n",
    "        n_zero = np.where(np.all(entrada == 0, axis=1))[0].size\n",
    "        print(f\"[Visualización] test_idx={idx_vis} | trazas anuladas en ese shot={n_zero}\")\n",
    "        visualizar_comparacion(entrada, pred, real, titulo_extra=f\"(Test idx={idx_vis}, {pct}%)\")\n",
    "\n",
    "        trazas_eliminadas = np.where(np.all(entrada == 0, axis=1))[0]\n",
    "        trazas_a_mostrar = trazas_eliminadas[:3] if len(trazas_eliminadas) >= 3 else trazas_eliminadas\n",
    "        if len(trazas_a_mostrar) > 0:\n",
    "            tiempo = np.arange(real.shape[1])\n",
    "            plt.figure(figsize=(30, 4))\n",
    "            for k, traza_idx in enumerate(trazas_a_mostrar):\n",
    "                plt.subplot(1, len(trazas_a_mostrar), k+1)\n",
    "                plt.plot(tiempo, real[traza_idx], label='Real', linewidth=1.5)\n",
    "                plt.plot(tiempo, pred[traza_idx], label='Predicho', linewidth=1.5)\n",
    "                plt.title(f\"Traza eliminada #{traza_idx}\")\n",
    "                plt.xlabel(\"Tiempo\"); plt.ylabel(\"Amplitud\")\n",
    "                plt.legend(); plt.grid(True)\n",
    "            plt.suptitle(f\"Comparación real vs predicho - Shot {idx_vis} - {pct}%\")\n",
    "            plt.tight_layout(); plt.show()\n",
    "        else:\n",
    "            print(\"⚠ Ese shot de test no tenía trazas anuladas para mostrar trazas individuales.\")\n",
    "\n",
    "    m_removed, (shots_used, total_removed) = eval_metrics_removed_only(model, Xe, Ye, device, return_counts=True)\n",
    "    resultados_metricas[f\"{pct}\"] = m_removed\n",
    "    print(f\"[Métricas {pct}%] usados {shots_used} shots | trazas anuladas evaluadas={total_removed} | {m_removed}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for pct, curva in curvas_loss.items():\n",
    "    plt.plot(range(1, len(curva)+1), curva, label=f\"{pct}%\")\n",
    "plt.title(\"Curvas de pérdida por submuestreo (1 - SSIM)\")\n",
    "plt.xlabel(\"Época\"); plt.ylabel(\"Pérdida\")\n",
    "plt.legend(title=\"Submuestreo\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Resultados de métricas (diccionario) ===\")\n",
    "print(resultados_metricas)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utah_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
